{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-88a6af6c846c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def initial_ETLs(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = (df['Date'].dt.strftime(\"%Y\")).astype(int)\n",
    "    df['Week'] = df['Date'].dt.week\n",
    "    return df\n",
    "def final_ETLs(df):\n",
    "    # Converting IsHoliday from True/False to 1/0\n",
    "    df['IsHoliday'] = df['IsHoliday'].astype(int)\n",
    "    # Converting StoreType A,B,C to 1,2,3\n",
    "    df = df.replace({'Type' : { 'A': 1,'B' :2,'C':3 }})\n",
    "    return df\n",
    "def describle_data(df,dname):\n",
    "    recs    = len(df)\n",
    "    nstores = df['Store'].nunique()\n",
    "    ndepart = df['Dept'].nunique()\n",
    "    min_wks = df['Date'].min().strftime('%b %d,%Y')\n",
    "    max_wks = df['Date'].max().strftime('%b %d,%Y')\n",
    "    print(f\"The {dname} data has {recs} records {nstores} stores and {ndepart} departments from {min_wks} to {max_wks}\")\n",
    "def get_act_vs_prd(dprd,ptitle='test',lcol='blue'):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    xx  = dprd['Week'].astype(str)\n",
    "    yy1 = dprd['Weekly_Sales_Actual']\n",
    "    yy2 = dprd['Weekly_Sales_Predicted']\n",
    "    plt.plot(xx, yy1, linewidth=2 ,color='black',label='Actual')\n",
    "    plt.plot(xx, yy2, linewidth=2, color=lcol, linestyle=\"--\", label='Predict')\n",
    "    plt.xlabel('2012 WEEKS')\n",
    "    plt.ylabel('Sales Volume')\n",
    "    plt.grid()\n",
    "    plt.title(ptitle)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def rae(y_test, y_pred):\n",
    "    return 'RAE', np.sum(np.abs(y_pred - y_test)) / np.sum(np.abs(np.mean(y_test) - y_test)), False\n",
    "def get_linear_regression(dtrain,dtest,ftrs):\n",
    "    x_train = dtrain[ftrs].values.reshape(-1,len(ftrs))\n",
    "    x_test  = dtest[ftrs].values.reshape(-1,len(ftrs))\n",
    "    y_train = dtrain['Weekly_Sales']\n",
    "    model   = LinearRegression().fit(x_train, y_train)\n",
    "    dtest['Weekly_Sales_Predicted']   = model.predict(x_test)\n",
    "    dtest = dtest.rename(columns={'Weekly_Sales':'Weekly_Sales_Actual'})\n",
    "    dprd = dtest.groupby(['Year','Week'],as_index=False)[['Weekly_Sales_Actual','Weekly_Sales_Predicted']].sum()\n",
    "    act, prd = dtest['Weekly_Sales_Actual'],dtest['Weekly_Sales_Predicted']\n",
    "    rmse = str(round(np.sqrt(mean_squared_error(act,prd)),2))\n",
    "    r2sc = str(round(r2_score(act,prd),2))\n",
    "    ptitle = f'Linear Regression, n_features={len(ftrs)} | RMSE ={rmse} | R2Score ={r2sc}'\n",
    "    get_act_vs_prd(dprd,ptitle)\n",
    "    return dprd\n",
    "def get_rf_regression(dtrain, dtest, ftrs):\n",
    "    X_train = dtrain[ftrs]\n",
    "    Y_train = dtrain['Weekly_Sales']\n",
    "    mftr = len(ftrs)\n",
    "    print(f\"Random Forrest is starting with {mftr} features, please wait for less than 60 sec...\")\n",
    "    RF = RandomForestRegressor(n_estimators=58, max_depth=27, max_features=mftr, min_samples_split=3, min_samples_leaf=1)\n",
    "    RF.fit(X_train, Y_train)\n",
    "    X_test  = dtest[ftrs]\n",
    "    rf_prd = RF.predict(X_test)\n",
    "    rf_test = dtest.copy()\n",
    "    rf_test = rf_test.rename(columns={'Weekly_Sales':'Weekly_Sales_Actual'})\n",
    "    rf_test['Weekly_Sales_Predicted'] = rf_prd\n",
    "    drf = rf_test.groupby(['Year','Week'],as_index=False)[['Weekly_Sales_Actual','Weekly_Sales_Predicted']].sum()\n",
    "    act, prd = drf['Weekly_Sales_Actual'],drf['Weekly_Sales_Predicted']\n",
    "    rmse = str(round(np.sqrt(mean_squared_error(act,prd)),2))\n",
    "    r2sc = str(round(r2_score(act,prd),2))\n",
    "    ptitle = f'Random Forrest, n_features={mftr} | RMSE ={rmse} | R2Score ={r2sc}'\n",
    "    get_act_vs_prd(drf,ptitle,lcol='green')\n",
    "    return drf\n",
    "\n",
    "def get_lgbm_regression(dtrain,dtest,ftrs2):\n",
    "    start=time.time()\n",
    "    lg_test = dtest[ftrs2+['Year','Weekly_Sales']]\n",
    "    x_train, x_test=dtrain[ftrs2], dtest[ftrs2]\n",
    "    y_train, y_test=dtrain['Weekly_Sales'], dtest['Weekly_Sales']\n",
    "    leaves= 50 # Number of leaves in a tree (control complexity of tree)\n",
    "    learn_rate = 0.05 # Step size towards minimum of a loss funtion\n",
    "    estimators=1000 # Number of attempts to estimate the best fit\n",
    "    early_rounds = 5  # Stop training if it doesn't improve for 5 rounds\n",
    "    mftrs = len(ftrs2)\n",
    "    print(f\"LGBM is starting with {mftrs} features, please wait for less than 60 sec...\")\n",
    "    # First training with L1 evaluation metric (default)\n",
    "    gbm = lgb.LGBMRegressor(num_leaves=leaves,learning_rate=learn_rate,n_estimators=estimators)\n",
    "    gbm.fit(x_train, y_train, eval_set=[(x_test, y_test)], eval_metric='l1',early_stopping_rounds=early_rounds,verbose=-1)\n",
    "    y_pred = gbm.predict(x_test, num_iteration=gbm.best_iteration_)\n",
    "\n",
    "    print('Starting training with custom eval function...')\n",
    "    # Second training with custom evaluaion metric, for example, RAE in this case\n",
    "    gbm.fit(x_train, y_train,eval_set=[(x_test, y_test)],eval_metric=[rae],early_stopping_rounds=early_rounds,verbose=-1)\n",
    "    y_pred = gbm.predict(x_test, num_iteration=gbm.best_iteration_)\n",
    "    lg_test['Weekly_Sales_Predicted']= y_pred\n",
    "\n",
    "    lg_test = lg_test.rename(columns={'Weekly_Sales':'Weekly_Sales_Actual'})\n",
    "    dlg = lg_test.groupby(['Year','Week'],as_index=False)[['Weekly_Sales_Actual','Weekly_Sales_Predicted']].sum()\n",
    "    act, prd = dlg['Weekly_Sales_Actual'],dlg['Weekly_Sales_Predicted']\n",
    "    rmse = str(round(np.sqrt(mean_squared_error(act,prd)),2))\n",
    "    r2sc = str(round(r2_score(act,prd),2))\n",
    "    ptitle = f'LGBM, n_features={mftrs} | RMSE ={rmse} | R2Score ={r2sc}'\n",
    "    get_act_vs_prd(dlg,ptitle,lcol='red')\n",
    "    end=time.time()\n",
    "    time_sec = int(round((end-start),0))\n",
    "    print(f\"LGBM completes its {estimators} rounds in {time_sec}sec\")\n",
    "    return dlg\n",
    "\n",
    "def compare_models(dlg2,drf2,dlr2):\n",
    "    dmod1 = dlg2.copy()\n",
    "    dmod2 = drf2.copy()\n",
    "    mcol  = ['Year','Week']\n",
    "    dmod1 = dmod1.rename(columns={'Weekly_Sales_Predicted':'LGBM'})\n",
    "    dmod2 = dmod2.rename(columns={'Weekly_Sales_Predicted':'RF'})\n",
    "    dmod  = dmod1.merge(dmod2[mcol+['RF']],on=mcol, how='left')\n",
    "    dmod = dmod.merge(dlr2[mcol+['Weekly_Sales_Predicted']], on=mcol,how='left')\n",
    "    dprd = dmod.rename(columns={'Weekly_Sales_Predicted':'LR', 'Weekly_Sales_Actual':'Actual'})\n",
    "    plt.figure(figsize=(12,6))\n",
    "    xx  = dprd['Week'].astype(str)\n",
    "    y1, y2, y3, y4 = dprd['Actual'], dprd['LR'], dprd['RF'], dprd['LGBM']\n",
    "    plt.plot(xx, y1, linewidth=2 ,color='black',label='Actual')\n",
    "    plt.plot(xx, y2, linewidth=2, color='blue', linestyle=\"--\", label='LR')\n",
    "    plt.plot(xx, y4, linewidth=2, color='red', linestyle=\"--\", label='LGBM')\n",
    "    plt.plot(xx, y3, linewidth=2, color='green', linestyle=\"--\", label='RF')\n",
    "    \n",
    "    plt.xlabel('2012 WEEKS')\n",
    "    plt.ylabel('Sales Volume')\n",
    "    plt.grid()\n",
    "    plt.title('Linear Regression(LR) Vs Random Forrest(RF) | n_features=5 Model')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "path=os.getcwd()+'/Input/'\n",
    "stores       = pd.read_csv(path+'stores.csv')\n",
    "raw_features = pd.read_csv(path+'features.csv')\n",
    "draw         = pd.read_csv(path+'walmart_data.csv')\n",
    "\n",
    "merger_cols =['Store','Date','IsHoliday']\n",
    "#Visually check nulls in raw_features\n",
    "print(raw_features.isnull().mean()*100)\n",
    "sns.heatmap(raw_features.isnull())\n",
    "plt.show()\n",
    "#Drop Coloumns having more than 60% nan, and filling others nan\n",
    "markdown_cols = [col for col in raw_features.columns if 'MarkDown' in col]\n",
    "features = raw_features.drop(markdown_cols,axis=1)\n",
    "features['CPI']= features['CPI'].fillna(features['CPI'].mean())\n",
    "features['Unemployment']= features['Unemployment'].fillna(features['Unemployment'].mean())\n",
    "#Heat map after fixing nulls\n",
    "sns.heatmap(features.isnull())\n",
    "plt.show()\n",
    "#What are store Types?\n",
    "fig = px.bar(stores, x='Store', y='Size', color='Type', title=f\"Walmart Store Types\")\n",
    "fig.show()\n",
    "#Combine Stores and Features\n",
    "dsf = stores.merge(features,on=['Store'],how='left') \n",
    "#Combine store and feature with the raw data\n",
    "df1 = draw.merge(dsf,on=merger_cols,how='left')\n",
    "# Get Necessary ETLs\n",
    "df  = initial_ETLs(df1.copy())\n",
    "#Describe overal data\n",
    "describle_data(df.copy(),'total')\n",
    "#Split data into train and test\n",
    "split_point = (df['Year']==2012) & (df['Week']>10)\n",
    "dtrain, dtest = df[~(split_point)], df[(split_point)]\n",
    "#Describe train/test data\n",
    "describle_data(dtrain.copy(),'train')\n",
    "describle_data(dtest.copy(),'test')\n",
    "#Describing train data statistics\n",
    "print(features[['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']].describe())\n",
    "#Departmentwise View of sale\n",
    "dprtm = df.groupby(['Dept','Week'],as_index=False)['Weekly_Sales'].sum()\n",
    "fig = px.line(dprtm, x='Week', y='Weekly_Sales', color='Dept', title=f\"Department-wise Weekly Sales\")\n",
    "fig.show()\n",
    "#Yearwise view of sale\n",
    "dstr = df.groupby(['Week','Type'],as_index=False)['Weekly_Sales'].sum()\n",
    "fig = px.line(dstr, x='Week', y='Weekly_Sales', color='Type', title=f\"Weekly Sales\")\n",
    "fig.show()\n",
    "#Visually check weekly sales trend for all years\n",
    "dwkly = df.groupby(['Year','Week'],as_index=False)['Weekly_Sales'].sum()\n",
    "fig = px.line(dwkly, x='Week', y='Weekly_Sales', color='Year', title=f\"Year-wise Weekly Sales\")\n",
    "fig.show()\n",
    "#Final ETL before using ML\n",
    "dtrain = final_ETLs(dtrain.copy())\n",
    "#Correlation Studies\n",
    "fig,ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(dtrain.corr(),linewidth=2,cbar_kws={\"shrink\":.7},annot=True)\n",
    "ax.set_ylim(0, 10)\n",
    "fig.show()\n",
    "# Features to consider in Forecasting\n",
    "ftrs1 = ['Week','Store','Dept','IsHoliday']\n",
    "ftrs2 = ['Week','Store','Dept','IsHoliday','Size']\n",
    "# Multivariate Linear Regressions\n",
    "dlr1 = get_linear_regression(dtrain.copy(),dtest.copy(), ftrs1)\n",
    "dlr2 = get_linear_regression(dtrain.copy(),dtest.copy(), ftrs2)\n",
    "# LGBM Regressions\n",
    "dlg1 = get_lgbm_regression(dtrain.copy(),dtest.copy(),ftrs1)\n",
    "dlg2 = get_lgbm_regression(dtrain.copy(),dtest.copy(),ftrs2)\n",
    "# Random Forrest Regressions\n",
    "drf1 = get_rf_regression(dtrain.copy(), dtest.copy(), ftrs1)\n",
    "drf2 = get_rf_regression(dtrain.copy(), dtest.copy(), ftrs2)\n",
    "#Comparison of two Modeling Techniques\n",
    "compare_models(dlg2.copy(),drf2.copy(),dlr2.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dtrain[ftrs].values.reshape(-1,len(ftrs))\n",
    "x_test  = dtest[ftrs].values.reshape(-1,len(ftrs))\n",
    "    y_train = dtrain['Weekly_Sales']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
